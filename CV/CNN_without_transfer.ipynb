{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilmark0/Agile-Manufacturing-TDK-/blob/main/CV/CNN_without_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "56TKwtITQGS4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYg8phKTQJcr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Ensure the Kaggle API credentials are set up\n",
        "kaggle_api_path = os.path.expanduser(\"~/.kaggle\")\n",
        "if not os.path.exists(kaggle_api_path):\n",
        "    os.makedirs(kaggle_api_path)\n",
        "\n",
        "# Path to the Kaggle API key file (replace 'your_kaggle_json_path' with your actual path if needed)\n",
        "kaggle_json_path = r\"C:\\Users\\bilma\\Downloads\\kaggle.json\"\n",
        "if os.path.exists(kaggle_json_path):\n",
        "    os.system(f\"cp {kaggle_json_path} {kaggle_api_path}/kaggle.json\")\n",
        "    os.chmod(f\"{kaggle_api_path}/kaggle.json\", 0o600)\n",
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d markbilszky/agile-manufacturing-tdk --unzip\n",
        "\n",
        "print(\"Dataset downloaded successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dULA_2FRQZFX"
      },
      "outputs": [],
      "source": [
        "data_dir = '/path/to/your/faulty_directory'\n",
        "img_height, img_width = 240, 380\n",
        "\n",
        "# Data generator with augmentation and validation split\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.4,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.1  # Use 10% of the data for validation\n",
        ")\n",
        "\n",
        "# Training data generator\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'  # Set as training data\n",
        ")\n",
        "\n",
        "# Validation data generator\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'  # Set as validation data\n",
        ")\n",
        "\n",
        "# Build the Custom CNN Model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Block 1\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Convolutional Block 2\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Convolutional Block 3\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Convolutional Block 4\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Flatten and Fully Connected Layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))  # Dense layer with 512 neurons\n",
        "model.add(Dropout(0.5))  # Dropout to prevent overfitting\n",
        "model.add(Dense(256, activation='relu'))  # Dense layer with 256 neurons\n",
        "model.add(Dropout(0.5))  # Additional dropout\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model with a binary cross-entropy loss function for binary classification\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set up early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,  # Increased epochs to take advantage of larger dataset\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f'Validation Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/object_detection_custom_cnn_model.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
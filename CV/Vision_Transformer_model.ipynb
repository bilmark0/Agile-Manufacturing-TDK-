{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHb1roak0YXm6LiSxumaUl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilmark0/Agile-Manufacturing-TDK-/blob/main/CV/Vision_Transformer_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "id": "-4eNvsDg4pj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56TKwtITQGS4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import sys\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the kaggle.json file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move the uploaded file to the .kaggle directory\n",
        "kaggle_api_path = os.path.expanduser(\"~/.kaggle\")\n",
        "if not os.path.exists(kaggle_api_path):\n",
        "    os.makedirs(kaggle_api_path)\n",
        "\n",
        "# Ensure the file is set with proper permissions\n",
        "kaggle_json_path = next(iter(uploaded))  # Get the uploaded filename\n",
        "os.rename(kaggle_json_path, f\"{kaggle_api_path}/kaggle.json\")\n",
        "os.chmod(f\"{kaggle_api_path}/kaggle.json\", 0o600)\n",
        "\n",
        "# Download the dataset from Kaggle\n",
        "!kaggle datasets download -d markbilszky/agile-manufacturing-tdk --unzip\n",
        "\n",
        "print(\"Dataset downloaded successfully.\")"
      ],
      "metadata": {
        "id": "1Kho_Ag8QWAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project='your_project_name')\n",
        "\n",
        "data_dir = '/path/to/your/faulty_directory'\n",
        "img_height, img_width = 240, 380\n",
        "\n",
        "# Data generator with validation split\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "# Training and validation data generators\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Define the Vision Transformer model\n",
        "def create_vit_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(16, (3, 3), padding='same')(inputs)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Reshape((-1, x.shape[-1]))(x)  # Reshape for transformer\n",
        "\n",
        "    # Transformer block\n",
        "    for _ in range(4):  # 4 transformer blocks\n",
        "        x_res = x\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=16)(x, x)\n",
        "        x = layers.Add()([x_res, attention_output])\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        x_res = x\n",
        "        x = layers.Dense(64, activation='relu')(x)\n",
        "        x = layers.Dense(x.shape[-1])(x)\n",
        "        x = layers.Add()([x_res, x])\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Create and compile the model\n",
        "model = create_vit_model((img_height, img_width, 3))\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set up early stopping and model checkpoint\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_model.keras',  # Save the best model in Keras format\n",
        "    monitor='val_loss',  # Metric to monitor\n",
        "    save_best_only=True,  # Save only the best model\n",
        "    mode='min',  # Minimize the validation loss\n",
        "    verbose=1  # Verbose output for logging\n",
        ")\n",
        "\n",
        "# Train the model with W&B callback\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping, model_checkpoint, WandbCallback()]  # Add W&B callback\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f'Validation Loss: {loss}, Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "dULA_2FRQZFX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPn/IvX51sAwN5tayC3SMRV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilmark0/Agile-Manufacturing-TDK-/blob/main/CV/Vision_Transformer_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "id": "-4eNvsDg4pj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56TKwtITQGS4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import sys\n",
        "from google.colab import files\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the kaggle.json file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move the uploaded file to the .kaggle directory\n",
        "kaggle_api_path = os.path.expanduser(\"~/.kaggle\")\n",
        "if not os.path.exists(kaggle_api_path):\n",
        "    os.makedirs(kaggle_api_path)\n",
        "\n",
        "# Ensure the file is set with proper permissions\n",
        "kaggle_json_path = next(iter(uploaded))  # Get the uploaded filename\n",
        "os.rename(kaggle_json_path, f\"{kaggle_api_path}/kaggle.json\")\n",
        "os.chmod(f\"{kaggle_api_path}/kaggle.json\", 0o600)\n",
        "\n",
        "# Download the dataset from Kaggle\n",
        "!kaggle datasets download -d markbilszky/agile-manufacturing-tdk --unzip\n",
        "\n",
        "print(\"Dataset downloaded successfully.\")"
      ],
      "metadata": {
        "id": "1Kho_Ag8QWAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your paths here\n",
        "base_path = './'  # Replace with the directory containing Reference, error_2, and error_3\n",
        "new_folder_path = os.path.join(base_path, 'training_data')\n",
        "\n",
        "# Create the new folder\n",
        "os.makedirs(new_folder_path, exist_ok=True)\n",
        "\n",
        "# Move the folders\n",
        "folders_to_move = ['Reference', 'error_2', 'error_3']\n",
        "for folder_name in folders_to_move:\n",
        "    shutil.move(os.path.join(base_path, folder_name), new_folder_path)\n",
        "\n",
        "print(\"Folders moved successfully!\")"
      ],
      "metadata": {
        "id": "dtFNg2RDzIWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0WRY39DGzK06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "\n",
        "# Sinusoidal learning rate callback\n",
        "class SinusoidalLearningRate(callbacks.Callback):\n",
        "    def __init__(self, max_lr, min_lr, total_epochs):\n",
        "        super(SinusoidalLearningRate, self).__init__()\n",
        "        self.max_lr = max_lr\n",
        "        self.min_lr = min_lr\n",
        "        self.total_epochs = total_epochs\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        lr = self.min_lr + (self.max_lr - self.min_lr) * (0.5 * (1 + math.sin(2 * math.pi * epoch / self.total_epochs)))\n",
        "        self.model.optimizer.learning_rate.assign(lr)\n",
        "        print(f\"Epoch {epoch + 1}: Learning rate is {lr:.6f}\")\n",
        "\n",
        "# Hyperparameters for the sinusoidal learning rate\n",
        "max_lr = 0.002  # Slightly increased max_lr\n",
        "min_lr = 0.0001\n",
        "total_epochs = 1000\n",
        "\n",
        "# Use the sinusoidal learning rate in the callbacks\n",
        "sinusoidal_lr_callback = SinusoidalLearningRate(max_lr=max_lr, min_lr=min_lr, total_epochs=total_epochs)\n",
        "\n",
        "data_dir = '/path/to/your/faulty_directory'\n",
        "img_height, img_width = 240, 380\n",
        "\n",
        "# Enhanced data generator with more augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,  # New data augmentation: rotation\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.8, 1.2],  # New augmentation: brightness adjustment\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "# Training and validation data generators\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',  # Updated for multi-class classification\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Define the Vision Transformer model\n",
        "def create_vit_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(16, (3, 3), padding='same', activation='relu', kernel_initializer='he_normal', kernel_regularizer='l2')(inputs)  # Added L2 regularization\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Reshape for transformer input\n",
        "    x = layers.Reshape((-1, x.shape[-1]))(x)\n",
        "\n",
        "    # Transformer block\n",
        "    for _ in range(4):  # Number of transformer blocks\n",
        "        x_res = x\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=16)(x, x)  # Updated key_dim for complexity\n",
        "        x = layers.Add()([x_res, attention_output])\n",
        "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        x_res = x\n",
        "        x = layers.Dense(128, activation='relu', kernel_regularizer='l2')(x)  # Enhanced dense layer\n",
        "        x = layers.Dropout(0.3)(x)  # Added dropout within transformer block\n",
        "        x = layers.Dense(x.shape[-1])(x)\n",
        "        x = layers.Add()([x_res, x])\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D()(x)  # Changed to GlobalAveragePooling1D for consistency\n",
        "    x = layers.Dense(512, activation='relu', kernel_regularizer='l2')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(3, activation='softmax')(x)  # Updated output for 3-class classification\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Create and compile the model\n",
        "model = create_vit_model((img_height, img_width, 3))\n",
        "model.compile(optimizer=Adam(learning_rate=max_lr),\n",
        "              loss='categorical_crossentropy',  # Updated loss for multi-class classification\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Set up early stopping and model checkpoint\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_model.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Train the model with the sinusoidal learning rate callback\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=total_epochs,\n",
        "    callbacks=[early_stopping, model_checkpoint, sinusoidal_lr_callback, reduce_lr]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(val_generator)\n",
        "print(f'Validation Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "dULA_2FRQZFX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}